Problem Statement:
Letâ€™s design a Web Crawler document on how to crawl a website site and save the images and text from the website.

step-1:

Web Crawler - 
A web crawler is a software program which browses the World Wide Web in a methodical and automated manner.
It collects documents by recursively fetching links from a set of starting pages.
Many sites, particularly search engines, use web crawling as a means of providing up-to-date data.
Search engines download all the pages to create an index on them to perform faster searches.
A web crawler works by discovering URLs and reviewing and categorizing web pages. 
Along the way, they find hyperlinks to other webpages and add them to the list of pages to crawl next. 
Web crawlers are smart and can determine the importance of each web page.
